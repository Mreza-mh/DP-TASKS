{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Optimizers"
      ],
      "metadata": {
        "id": "mGYQongalHNk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i1Mmrzc2fI8X"
      },
      "outputs": [],
      "source": [
        "import torch, torch.nn as nn, torch.optim as optim\n",
        "from sklearn.datasets import make_moons\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "# Prepare data\n",
        "X, y = make_moons(n_samples=2000, noise=0.2, random_state=0)\n",
        "X = torch.tensor(X, dtype=torch.float32)\n",
        "y = torch.tensor(y, dtype=torch.long)\n",
        "ds = TensorDataset(X, y)\n",
        "loader = DataLoader(ds, batch_size=128, shuffle=True)\n",
        "\n",
        "# Small MLP\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(2, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 2)\n",
        "        )\n",
        "    def forward(self, x): return self.net(x)\n",
        "\n",
        "def train_optimizer(opt_name, lr=1e-3, epochs=60):\n",
        "    torch.manual_seed(0)\n",
        "    model = MLP()\n",
        "    if opt_name=='sgd':\n",
        "        opt = optim.SGD(model.parameters(), lr=lr)\n",
        "    elif opt_name=='sgd_mom':\n",
        "        opt = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
        "    elif opt_name=='adam':\n",
        "        opt = optim.Adam(model.parameters(), lr=lr)\n",
        "    elif opt_name=='adamw':\n",
        "        opt = optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4)\n",
        "    else:\n",
        "        raise ValueError(opt_name)\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "    sched_step = lr_sched.StepLR(opt, step_size=20, gamma=0.1)\n",
        "    losses = []\n",
        "    for epoch in range(epochs):\n",
        "        epoch_loss = 0.0\n",
        "        for xb, yb in loader:\n",
        "            opt.zero_grad()\n",
        "            out = model(xb)\n",
        "            loss = loss_fn(out, yb)\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "\n",
        "            sched_step.step()\n",
        "            epoch_loss += loss.item()\n",
        "        losses.append(epoch_loss/len(loader))\n",
        "    return losses"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gradient Norms & Gradient Clipping"
      ],
      "metadata": {
        "id": "hba5xUXklVLQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n"
      ],
      "metadata": {
        "id": "pBdo3CWNlYN4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.nn.utils.clip_grad_value_(model.parameters(), clip_value=0.5)\n"
      ],
      "metadata": {
        "id": "UsSae9cRwtOq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Learning Rate Schedules"
      ],
      "metadata": {
        "id": "2CucGvislvAU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim.lr_scheduler as lr_sched\n",
        "\n",
        "sched_step = lr_sched.StepLR(opt, step_size=20, gamma=0.1)\n",
        "sched_multi = lr_sched.MultiStepLR(opt, milestones=[30, 60, 90], gamma=0.1)\n",
        "sched_plateau = lr_sched.ReduceLROnPlateau(opt, factor=0.5, patience=5)\n",
        "sched_cosine = lr_sched.CosineAnnealingLR(opt, T_max=50)\n",
        "sched_warmup_cosine = lr_sched.CosineAnnealingWarmRestarts(opt, T_0=10)\n"
      ],
      "metadata": {
        "id": "HSIu3mr3lwhd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mixed Precision (AMP)"
      ],
      "metadata": {
        "id": "pNHlsQBdmGks"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.cuda.amp import autocast, GradScaler\n",
        "\n",
        "scaler = GradScaler()\n",
        "\n",
        "with autocast():\n",
        "    output = model(x)\n",
        "    loss = loss_fn(output, y)\n",
        "\n",
        "scaler.scale(loss).backward()\n",
        "scaler.step(opt)\n",
        "scaler.update()\n"
      ],
      "metadata": {
        "id": "ge0eLhntmIRF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Augmentation"
      ],
      "metadata": {
        "id": "E8ne3QDOxD1x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "\n",
        "augment_basic = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "])\n",
        "\n",
        "augment_color = transforms.Compose([\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
        "])\n",
        "\n",
        "augment_geometric = transforms.Compose([\n",
        "    transforms.RandomRotation(20),\n",
        "    transforms.RandomAffine(0, translate=(0.1,0.1)),\n",
        "])\n",
        "\n",
        "augment_strong = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.RandomApply([transforms.ColorJitter()], p=0.8),\n",
        "    transforms.RandomGrayscale(p=0.2),\n",
        "])\n"
      ],
      "metadata": {
        "id": "ozPkawC1wirE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Weight Decay"
      ],
      "metadata": {
        "id": "67rm7Q7rxHtc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "opt = optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-2)  # strong\n",
        "opt = optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)  # moderate\n",
        "opt = optim.SGD(model.parameters(), lr=0.01, weight_decay=5e-4)   # typical for CNNs\n"
      ],
      "metadata": {
        "id": "kzdo1SxjwmN3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Early Stopping"
      ],
      "metadata": {
        "id": "BYgEhbPuxJ5C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_loss = float('inf')\n",
        "patience = 10\n",
        "counter = 0\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    train(...)\n",
        "    val_loss = validate(...)\n",
        "\n",
        "    if val_loss < best_loss:\n",
        "        best_loss = val_loss\n",
        "        counter = 0\n",
        "        torch.save(model.state_dict(), \"best.pt\")\n",
        "    else:\n",
        "        counter += 1\n",
        "\n",
        "    if counter >= patience:\n",
        "        print(\"Early stopping triggered.\")\n",
        "        break\n"
      ],
      "metadata": {
        "id": "jmDhM91ixAn4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise:\n",
        "Reach strong accuracy on CIFAR-10 by applying the techniques (data augmentation, optimizer selection, weight decay, schedulers, gradient clipping, AMP, Early Stopping)."
      ],
      "metadata": {
        "id": "U5jjpWyAnGYa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# 1ï¸âƒ£ Ù†ØµØ¨ Ùˆ Ø§ÛŒÙ…Ù¾ÙˆØ±Øª Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡â€ŒÙ‡Ø§\n",
        "# ==========================================\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# ==========================================\n",
        "# 2ï¸âƒ£ Ø§Ù†ØªØ®Ø§Ø¨ Ø¯Ø³ØªÚ¯Ø§Ù‡ (GPU Ø§Ú¯Ø± Ù…ÙˆØ¬ÙˆØ¯ Ø¨Ø§Ø´Ø¯)\n",
        "# ==========================================\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# ==========================================\n",
        "# 3ï¸âƒ£ Data Augmentation Ùˆ Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§\n",
        "# ==========================================\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
        "])\n",
        "\n",
        "# ==========================================\n",
        "# 4ï¸âƒ£ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ùˆ Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¯ÛŒØªØ§Ø³Øª CIFAR-10\n",
        "# ==========================================\n",
        "train_dataset = torchvision.datasets.CIFAR10(\n",
        "    root=\"./data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=train_transform\n",
        ")\n",
        "\n",
        "test_dataset = torchvision.datasets.CIFAR10(\n",
        "    root=\"./data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=test_transform\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=128,\n",
        "    shuffle=True,\n",
        "    num_workers=2\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=128,\n",
        "    shuffle=False,\n",
        "    num_workers=2\n",
        ")\n",
        "\n",
        "# ==========================================\n",
        "# 5ï¸âƒ£ Ù…Ø¯Ù„ (ResNet18)\n",
        "# ==========================================\n",
        "model = torchvision.models.resnet18(num_classes=10)\n",
        "model = model.to(device)\n",
        "\n",
        "# ==========================================\n",
        "# 6ï¸âƒ£ Loss Function Ùˆ Optimizer + Weight Decay\n",
        "# ==========================================\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = optim.AdamW(\n",
        "    model.parameters(),\n",
        "    lr=0.001,\n",
        "    weight_decay=0.01\n",
        ")\n",
        "\n",
        "# ==========================================\n",
        "# 7ï¸âƒ£ Scheduler (Ú©Ù†ØªØ±Ù„ Learning Rate)\n",
        "# ==========================================\n",
        "scheduler = optim.lr_scheduler.StepLR(\n",
        "    optimizer,\n",
        "    step_size=10,\n",
        "    gamma=0.5\n",
        ")\n",
        "\n",
        "# ==========================================\n",
        "# 8ï¸âƒ£ AMP (Mixed Precision)\n",
        "# ==========================================\n",
        "scaler = GradScaler()\n",
        "\n",
        "# ==========================================\n",
        "# 9ï¸âƒ£ Early Stopping ØªÙ†Ø¸ÛŒÙ…Ø§Øª\n",
        "# ==========================================\n",
        "best_accuracy = 0.0\n",
        "patience = 5\n",
        "no_improve_epochs = 0\n",
        "epochs = 40\n",
        "\n",
        "# ==========================================\n",
        "# ðŸ”Ÿ Ø­Ù„Ù‚Ù‡ Ø¢Ù…ÙˆØ²Ø´ Ùˆ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ\n",
        "# ==========================================\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Mixed Precision\n",
        "        with autocast(enabled=(device.type == \"cuda\")):\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "\n",
        "        # Gradient Clipping\n",
        "        scaler.unscale_(optimizer)\n",
        "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    # ==================================================\n",
        "    # Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ù…Ø¯Ù„ Ø±ÙˆÛŒ Test Set\n",
        "    # ==================================================\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = 100.0 * correct / total\n",
        "    avg_loss = running_loss / len(train_loader)\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{epochs}] | Loss: {avg_loss:.4f} | Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "    # ==================================================\n",
        "    # Early Stopping\n",
        "    # ==================================================\n",
        "    if accuracy > best_accuracy:\n",
        "        best_accuracy = accuracy\n",
        "        torch.save(model.state_dict(), \"best_cifar10_model.pth\")\n",
        "        no_improve_epochs = 0\n",
        "        print(\">> New best model saved\")\n",
        "    else:\n",
        "        no_improve_epochs += 1\n",
        "\n",
        "    if no_improve_epochs >= patience:\n",
        "        print(\">> Early stopping activated\")\n",
        "        break\n",
        "\n",
        "print(\"Training finished\")\n",
        "print(f\"Best Accuracy: {best_accuracy:.2f}%\")\n"
      ],
      "metadata": {
        "id": "gnmYJ_50qUdO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5dd4adf9-d457-4288-ffb6-ebb38b855ca8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 170M/170M [00:04<00:00, 39.6MB/s]\n",
            "/tmp/ipython-input-1202253461.py:94: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()\n",
            "/tmp/ipython-input-1202253461.py:117: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(enabled=(device.type == \"cuda\")):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/40] | Loss: 1.5717 | Accuracy: 53.96%\n",
            ">> New best model saved\n",
            "Epoch [2/40] | Loss: 1.2383 | Accuracy: 60.13%\n",
            ">> New best model saved\n",
            "Epoch [3/40] | Loss: 1.0884 | Accuracy: 64.69%\n",
            ">> New best model saved\n",
            "Epoch [4/40] | Loss: 0.9823 | Accuracy: 67.89%\n",
            ">> New best model saved\n",
            "Epoch [5/40] | Loss: 0.9016 | Accuracy: 68.93%\n",
            ">> New best model saved\n",
            "Epoch [6/40] | Loss: 0.8377 | Accuracy: 72.22%\n",
            ">> New best model saved\n",
            "Epoch [7/40] | Loss: 0.7973 | Accuracy: 73.89%\n",
            ">> New best model saved\n",
            "Epoch [8/40] | Loss: 0.7592 | Accuracy: 74.61%\n",
            ">> New best model saved\n",
            "Epoch [9/40] | Loss: 0.7301 | Accuracy: 76.60%\n",
            ">> New best model saved\n",
            "Epoch [10/40] | Loss: 0.6960 | Accuracy: 76.88%\n",
            ">> New best model saved\n",
            "Epoch [11/40] | Loss: 0.6119 | Accuracy: 79.16%\n",
            ">> New best model saved\n",
            "Epoch [12/40] | Loss: 0.5838 | Accuracy: 80.27%\n",
            ">> New best model saved\n",
            "Epoch [13/40] | Loss: 0.5718 | Accuracy: 80.46%\n",
            ">> New best model saved\n",
            "Epoch [14/40] | Loss: 0.5570 | Accuracy: 80.69%\n",
            ">> New best model saved\n",
            "Epoch [15/40] | Loss: 0.5372 | Accuracy: 80.73%\n",
            ">> New best model saved\n",
            "Epoch [16/40] | Loss: 0.5277 | Accuracy: 80.87%\n",
            ">> New best model saved\n",
            "Epoch [17/40] | Loss: 0.5225 | Accuracy: 81.49%\n",
            ">> New best model saved\n",
            "Epoch [18/40] | Loss: 0.5008 | Accuracy: 81.56%\n",
            ">> New best model saved\n",
            "Epoch [19/40] | Loss: 0.4928 | Accuracy: 82.03%\n",
            ">> New best model saved\n",
            "Epoch [20/40] | Loss: 0.4845 | Accuracy: 82.18%\n",
            ">> New best model saved\n",
            "Epoch [21/40] | Loss: 0.4432 | Accuracy: 83.19%\n",
            ">> New best model saved\n",
            "Epoch [22/40] | Loss: 0.4277 | Accuracy: 83.56%\n",
            ">> New best model saved\n",
            "Epoch [23/40] | Loss: 0.4147 | Accuracy: 83.38%\n",
            "Epoch [24/40] | Loss: 0.4091 | Accuracy: 83.62%\n",
            ">> New best model saved\n",
            "Epoch [25/40] | Loss: 0.4072 | Accuracy: 83.76%\n",
            ">> New best model saved\n",
            "Epoch [26/40] | Loss: 0.3983 | Accuracy: 83.92%\n",
            ">> New best model saved\n",
            "Epoch [27/40] | Loss: 0.3944 | Accuracy: 83.41%\n",
            "Epoch [28/40] | Loss: 0.3854 | Accuracy: 83.52%\n",
            "Epoch [29/40] | Loss: 0.3820 | Accuracy: 83.74%\n",
            "Epoch [30/40] | Loss: 0.3735 | Accuracy: 83.58%\n",
            "Epoch [31/40] | Loss: 0.3488 | Accuracy: 84.25%\n",
            ">> New best model saved\n",
            "Epoch [32/40] | Loss: 0.3428 | Accuracy: 84.31%\n",
            ">> New best model saved\n",
            "Epoch [33/40] | Loss: 0.3383 | Accuracy: 84.03%\n",
            "Epoch [34/40] | Loss: 0.3310 | Accuracy: 84.23%\n",
            "Epoch [35/40] | Loss: 0.3276 | Accuracy: 84.23%\n",
            "Epoch [36/40] | Loss: 0.3270 | Accuracy: 84.27%\n",
            "Epoch [37/40] | Loss: 0.3257 | Accuracy: 84.01%\n",
            ">> Early stopping activated\n",
            "Training finished\n",
            "Best Accuracy: 84.31%\n"
          ]
        }
      ]
    }
  ]
}